# ML-DL Implementations
---

<details><summary>Activation Functions</summary>
  
| ID | Activation Function | Link |
| -- | ------------------- | ---- |
| 1  | Continuously-Differentiable Exponential Linear Unit (CELU) Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/celu_function.py) |
| 2  | Exponential Linear Unit (ELU) Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/elu_function.py) |
| 3  |Exponential ReLU Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/exponential_relu_function.py) |
| 4  | Gaussian Error Linear Unit (GELU) Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/gelu_function.py) |
| 5  | Gated Linear Unit (GLU) Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/glu_function.py) |
| 6  | Hard Sigmoid Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/hard_sigmoid_function.py) |
| 7  | Hard Swish (A Self-Gated / Silu) Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/hard_silu_function.py) |
| 8  | Hard Tanh Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/hard_tanh_function.py) | 
| 9  | Leaky ReLU Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/leaky_relu_activation_function.py) |
| 10 | Linear Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/linear_function.py) |
| 11 | Log Sigmoid Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/log_sigmoid_function.py) |
| 12 | Log Softmax Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/log_softmax_function.py) |
| 13 | Mish Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/mish_function.py) |
| 14 | Parameterized ReLU Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/parameterized_relu_function.py) |
| 15 | ReLU6 Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/relu6_function.py) |
| 16 | ReLU Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/relu_activation_function.py) |
| 17 | Scaled Exponential Linear Unit (SELU) Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/selu_function.py) |
| 18 | Sigmoid Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/sigmoid_activation_function.py) | 
| 19 | Softmax Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/softmax_activation_function.py) |
| 20 | Softplus Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/softplus_function.py) |
| 21 | Softsign Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/softsign_function.py) |
| 22 | Sparse Plus Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/sparse_plus_function.py) |
| 23 | Sparse Sigmoid Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/sparse_sigmoid_function.py) |
| 24 | Square Plus Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/square_plus_function.py) |
| 25 | Step Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/step_function.py) |
| 26 | Swish Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/swish_function.py) |
| 27 | Tanh Function | [Link](https://github.com/thealper2/ml-dl-implementations/blob/main/activation%20functions/tanh_function.py) |

</details>
